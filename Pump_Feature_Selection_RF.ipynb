{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Lab 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = pd.read_csv(\"data/Pump Sensors/prep_sensor.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.drop(['timestamp'], inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.machine_status = pd.Categorical(allData.machine_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.machine_status = allData.machine_status.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = allData.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Solution to Random Tree Question\n",
    "def runModel(train_features, train_labels, test_features, test_labels):\n",
    "        # create an instance based learner\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf = clf.fit(train_features, train_labels)\n",
    "    \n",
    "    # predict the class for an unseen example\n",
    "    results= clf.predict(test_features)\n",
    "    return metrics.accuracy_score(results, test_labels)\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    # open the data file \n",
    "    #allData = np.genfromtxt(\"data/Pump Sensors/prep_sensor.csv\", delimiter=\",\")\n",
    "    \n",
    "    # split the data into training and class data\n",
    "    y = allData[:, -1]\n",
    "    X = allData[:, 0:-1]\n",
    "    \n",
    "    # standarize all data\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    train_features, test_features, train_labels, test_labels = model_selection.train_test_split( X, y, test_size=0.2, random_state=1)\n",
    "   \n",
    "    accur = runModel(train_features, train_labels, test_features, test_labels)\n",
    "    print (\"Initial Accuracy \", accur)\n",
    "    \n",
    "    \n",
    "    # create a extra tree classifier to be used for feature selection\n",
    "    forest = RandomForestClassifier(n_estimators=250, random_state=0)\n",
    "    forest.fit(X, y)\n",
    "    \n",
    "    # importances contains the feature importance value for each metric\n",
    "    importances = forest.feature_importances_\n",
    "    \n",
    "    # argsort returns the indices that will sort the original array\n",
    "    sortedIndices = np.argsort(importances)\n",
    "    \n",
    "    print (importances, sortedIndices)\n",
    "   \n",
    "    \n",
    "    # iteratively remove the features with the lowest ranking and record accuracy\n",
    "    numberOfFeatures = []\n",
    "    accurKNN = []\n",
    "    \n",
    "    for num in range(0, 39):\n",
    "        \n",
    "        \n",
    "        numberOfFeatures.append(num)\n",
    "        \n",
    "        # obtain indices to delete by slicing the order indices from argsort function\n",
    "        indicesToDelete = sortedIndices[0:num+1]\n",
    "        # delete identified indices\n",
    "        train_features_new = np.delete(train_features, indicesToDelete, axis = 1)\n",
    "        test_features_new = np.delete(test_features, indicesToDelete, axis = 1)\n",
    "        \n",
    "        # run the model using updates feature training and test data\n",
    "        accur = runModel(train_features_new, train_labels, test_features_new, test_labels)\n",
    "        accurKNN.append(accur)\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features removed\")\n",
    "    plt.ylabel(\"Cross validation score \")\n",
    "    plt.plot(numberOfFeatures, accurKNN)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
