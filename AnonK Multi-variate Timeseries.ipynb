{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c48bb8",
   "metadata": {},
   "source": [
    "## Unsupervised Anomaly Detection in Multivariate Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b82da8",
   "metadata": {},
   "source": [
    "### Dataset 3 - Anonymous Multivariate Time Series (sourced from Kaggle)\n",
    "- Anonymous multivariate time series dataset from Kaggle\n",
    "- There are 509k samples with 11 (sensor channel type) features\n",
    "- Each instance / row is one moment in time.\n",
    "- The actual time step is unkown.\n",
    "- 443 rows are identified as rare, outliers / anomaly events (c.0.09%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504634db",
   "metadata": {},
   "source": [
    "**Models Evaluated**: \n",
    "* MODEL 1. PCA with Mahalonobis Distance\n",
    "* MODEL 2. K-means Clustering with Euclidean Distance\n",
    "* MODEL 3. One-class Support Vector Machine (SVM)\n",
    "* MODEL 4. Isolation Forest\n",
    "* MODEL 5. LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import PdM_functions as pdm # custom functions created for this project that are used in several notebooks\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.signal import freqz\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf53eb",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb46525",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be182e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, merge, clean some columns and assign a timestamp column\n",
    "df_set = pd.read_csv('data/Timeseries_Kaggle/TimeSeries.csv', sep = \",\")\n",
    "df_lab = pd.read_csv('data/Timeseries_Kaggle/labelsTimeSeries.csv', sep = \",\")\n",
    "df_set = pd.merge(df_set, df_lab, left_index=True, right_index=True)\n",
    "df_set['label'] = df_set['label'].map({0: 'Normal', 1:'Abnormal'})\n",
    "df_set.rename(columns = {'label': 'status'}, inplace = True)\n",
    "df_set['timestamp'] = df_set.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff78785",
   "metadata": {},
   "source": [
    "#### Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a data quality report for the numeric data\n",
    "pdm.generate_dq_num(df_set.drop(['timestamp', 'status'], axis = 1), df_set.columns.drop(['timestamp', 'status']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a data quality report for the other data\n",
    "df_set_other = df_set[['timestamp', 'status']]\n",
    "pdm.generate_dq_cat(df_set_other, df_set_other.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f9cfa",
   "metadata": {},
   "source": [
    "#### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick plot of data to review \n",
    "PLOT_ALL = True\n",
    "if PLOT_ALL:\n",
    "    plot_chans = df_set.columns.drop(['timestamp', 'status'])\n",
    "else:\n",
    "    plot_chans = ['v2']\n",
    "\n",
    "for sen in plot_chans:\n",
    "    df_set[[sen]].plot(figsize = (18, 4), color = 'black', marker = 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac89f5",
   "metadata": {},
   "source": [
    "#### Data Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc559d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 20\n",
    "fig, axs = plt.subplots(3, 4, sharey=True, tight_layout=True, figsize = (18, 12))\n",
    "axs = axs.ravel()\n",
    "for p, ref in enumerate(df_set.columns.drop(['status'])):\n",
    "    axs[p].hist(df_set[ref].values, bins=n_bins, label = ref, color = 'black')\n",
    "    axs[p].legend(loc = 'upper right')\n",
    "    #axs[p].set_title(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc7b417",
   "metadata": {},
   "source": [
    "Several of the distributions are unusual, and possibly indicate that the data could be synthetic. Sensors v4, v5 and v6 show very little variation as indentified in the data quality report above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_set.loc[:, df_set.columns.drop(['timestamp'])], hue='status')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de91225",
   "metadata": {},
   "source": [
    "#### Examine Status (Anomaly) Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize status over time for the data using sensor v5 as backdrop\n",
    "fig, ax = plt.subplots(figsize = (18, 4))\n",
    "ax.plot(df_set['v5'], color = 'grey', marker = 'o', zorder = 1, label = 'Sensor v5')\n",
    "anomaly_dat = df_set.loc[df_set['status'] == 'Abnormal', :]\n",
    "anomaly_dat = anomaly_dat.assign(status_bool = 1)\n",
    "ax.scatter(anomaly_dat.index, anomaly_dat['status'], color = 'red', marker = 'x', zorder = 1, label = 'Anomaly')\n",
    "#ax.set_xlim(105000, 120000),\n",
    "ax.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc84a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize machine status at one typical location (again using v5 as reference)\n",
    "fig, ax = plt.subplots(figsize = (18, 4))\n",
    "ax.plot(df_set['v5'], color = 'grey', marker = 'o', zorder = 1, label = 'Sensor v5')\n",
    "ax.scatter(anomaly_dat.index, anomaly_dat['status'], color = 'red', marker = 'X', s = 250, zorder = 1, label = 'Anomaly')\n",
    "ax.set_xlim(115030, 115110)\n",
    "ax.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42080901",
   "metadata": {},
   "source": [
    "The above zoomed view of one anomaly is typical of the dataset.  Each anomaly event is a short series of points, centered on the anomaly/event label (identied by the red 'X' in the above plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace55aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_pts = len(df_set.loc[df_set['status'] == 'Normal', :])\n",
    "anomal_pts = len(df_set.loc[df_set['status'] == 'Abnormal', :])\n",
    "print('No. of normal datapoints:', \"{:,}\".format(normal_pts))\n",
    "print('No. of anomaly datapoints:', \"{:,}\".format(anomal_pts))\n",
    "print('Anomaly percentage: ' + str(round(100*anomal_pts/normal_pts, 3)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c389e4",
   "metadata": {},
   "source": [
    "There is a significant class imbalance in the dataset.  This is quite common in predictive maintenance type problems (where recorded/labelled failures are usually quite rare.  Only 0.09% of datapoints are acually anomalies.  In order to imrove this, we will create anomaly windows centered on the anomaly label.  We will see later that this will bring the imbalance up to c.2%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06edf0ce",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.pyplot import figure\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numeric data\n",
    "df_num = df_set.drop(['status', 'timestamp'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45664774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try rolling means\n",
    "# df_num = df_num.rolling(3, min_periods=1).mean()\n",
    "# Window = 2 has no affect\n",
    "# Window = 3 marginal disimprovement\n",
    "# Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try fast fourier transform (FFT)\n",
    "cols_fft = df_num.columns\n",
    "df_num_fft = np.fft.fft(df_num)\n",
    "df_fft = pd.DataFrame()\n",
    "for c, ref in enumerate(cols_fft):    \n",
    "    #df_fft[ref] = np.abs(df_num[:,c]).tolist()\n",
    "    df_fft[ref] = df_num_fft[:,c].real.tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "feb5f43e",
   "metadata": {},
   "source": [
    "for ref in cols_fft: \n",
    "    X = df_fft[ref]\n",
    "    N = len(X)\n",
    "    n = np.arange(N)\n",
    "\n",
    "    # Define the sampling rate\n",
    "    sr = 1\n",
    "    T = N/sr\n",
    "    freq = n/T \n",
    "\n",
    "    plt.figure(figsize = (12, 6))\n",
    "    plt.plot(freq, np.abs(X), 'b')\n",
    "    plt.xlabel('Freq (Hz)')\n",
    "    plt.ylabel('FFT Amplitude |X(freq)|')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8506fc47",
   "metadata": {},
   "source": [
    "# Try band pass filter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "# Sample rate and desired cutoff frequencies (in Hz).\n",
    "fs = 10\n",
    "lowcut = 0.2\n",
    "highcut = 0.6\n",
    "\n",
    "df_num = np.fft.fft(df_num)\n",
    "df_fft_bp = pd.DataFrame()\n",
    "for c, ref in enumerate(cols_fft): \n",
    "    y = butter_bandpass_filter(df_fft[ref], lowcut, highcut, fs, order=6)\n",
    "    plt.plot(y, label='Filtered signal (%g Hz)') \n",
    "    plt.show()\n",
    "    df_fft_bp[ref] = y.tolist()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee2ee436",
   "metadata": {},
   "source": [
    "# Quick check of data\n",
    "print(df_fft.columns)\n",
    "PLOT_ALL = True\n",
    "if PLOT_ALL:\n",
    "    plot_chans = df_fft.columns\n",
    "else:\n",
    "    plot_chans = ['v2']\n",
    "\n",
    "for sen in plot_chans:\n",
    "    df_fft[[sen]].plot(figsize = (18, 4), color = 'black', marker = 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_num = df_fft\n",
    "#df_num = df_fft_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3bb203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data (standardise)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "df_set_scaled = pd.DataFrame(scaler.fit_transform(df_num), columns = df_num.columns, index = df_num.index)\n",
    "df_set_scaled['status'] = df_set['status']\n",
    "df_set_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ef6d1",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f050e64",
   "metadata": {},
   "source": [
    "The event labels are provided only for single points.  As stated in the dataset notes, each event is actually a series of consecutive events.  From data understanding and plotting of the events, it looks like 5-10 datapoints before and after the labelled event would capture the event.  Let's first check the min and max run lengths between anomaly labelled events in the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate run length encoding for the status column\n",
    "rle = [(k, sum(1 for i in g)) for k, g in groupby(df_set_scaled['status'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fda45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check run length streaks so we can pick a suitable window to use \n",
    "# to classify an anomaly window\n",
    "max_norm_streak = 0  \n",
    "min_norm_streak = len(rle)  \n",
    "for j in range(len(rle)):\n",
    "    if rle[j][0] == 'Normal':\n",
    "        chk_streak = int(rle[j][1])        \n",
    "        if chk_streak > max_norm_streak:\n",
    "            max_norm_streak = chk_streak\n",
    "        if chk_streak < min_norm_streak:\n",
    "            min_norm_streak = chk_streak    \n",
    "print('Max normal run length: ', max_norm_streak)\n",
    "print('Min normal run length: ', min_norm_streak)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a8b571",
   "metadata": {},
   "source": [
    "Let's pick 10 points as the transition window, anomaly windows will then typically be 20 datapoints long, with the actual anomaly label located in the middle.  In our modelling methods, we shall look to successfully identify the anomaly window as opposed to exactly identifying the actual anomaly label point.  This approach is more applicable for the unsupervised anomaly detection methodlogy that we are exploring.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign datapoints before & after the recorded anomaly to the 'anomaly window'\n",
    "trans_win = 10 # points before & after\n",
    "\n",
    "# Create map to reduce categories to two\n",
    "# Not really relevant here as there are only two categories to start with\n",
    "condition_map = {'Normal': 'Normal', 'Abnormal': 'Abnormal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a timestamp column to help with plotting\n",
    "df_set_scaled['timestamp'] = df_set_scaled.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd6585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the 'normal' and 'abonormal' dataset.\n",
    "This function will separate the normal data from the abnormal/anomaly data.\n",
    "Again, the anomaly data is n points before & after each anomaly labelled point.\n",
    "\"\"\"\n",
    "df_norm, df_abnorm = pdm.remove_segements(\n",
    "    segment_vec = df_set_scaled['status'],\n",
    "    mapping = condition_map,\n",
    "    dat = df_set_scaled,\n",
    "    trans_window = trans_win, \n",
    "    keep = 'Normal'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed8892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check row counts\n",
    "tot_rows = len(df_norm) + len(df_abnorm)\n",
    "print(f'No. of normal rows: {\"{:,}\".format(len(df_norm))} ({round(100*len(df_norm)/tot_rows)}%)')\n",
    "print(f'No. of abnorm rows: {\"{:,}\".format(len(df_abnorm))} ({round(100*len(df_abnorm)/tot_rows)})%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30b7fb",
   "metadata": {},
   "source": [
    "The abnormal data (anomaly windows) now make up approximately 2% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff726a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate numeric datasets for training and testing\n",
    "df_train = df_norm\n",
    "df_train = df_train.drop(['status', 'timestamp'], axis = 1)                      \n",
    "#df_train = df_train.iloc[500:,]\n",
    "\n",
    "df_test1 = df_abnorm\n",
    "df_test1 = df_test1.drop(['status', 'timestamp'], axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb62f2b",
   "metadata": {},
   "source": [
    "Most of the models that we will experiment with will be training on 'normal' data and testing on the 'abnormal' data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eead956",
   "metadata": {},
   "source": [
    "### MODEL 1.  Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PCA model (all compoments)\n",
    "n_comps = 10 # How many dimensions you want to reduce to\n",
    "pca = PCA(n_components = n_comps, svd_solver = 'full')\n",
    "\n",
    "# Compute PCA components for the training set\n",
    "X_train_PCA = pca.fit_transform(df_train)\n",
    "X_train_PCA = pd.DataFrame(X_train_PCA)\n",
    "X_train_PCA.index = df_train.index\n",
    "\n",
    "# Project the test data onto the PCA space\n",
    "X_test1_PCA = pca.transform(df_test1)\n",
    "X_test1_PCA = pd.DataFrame(X_test1_PCA)\n",
    "X_test1_PCA.index = df_test1.index\n",
    "\n",
    "# Print the explained variance\n",
    "# 3 decimal places and don't use scientific notation\n",
    "np.set_printoptions(precision = 3, suppress=True) \n",
    "print('Explained variance:', pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aebdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PC1 vs PC2 for training & test sets\n",
    "xlims = 20\n",
    "fig, axes = plt.subplots(1, 2, figsize = (12, 5))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios = [1, 1])\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.scatter(X_train_PCA.loc[:, 0], X_train_PCA.loc[:, 1], color = 'green')\n",
    "ax0.set_xlabel('PC1')\n",
    "ax0.set_ylabel('PC2')\n",
    "ax0.set_xlim(-xlims, xlims)\n",
    "ax0.set_ylim(-xlims, xlims)\n",
    "ax0.set_title('Training Data')\n",
    "\n",
    "ax1 = plt.subplot(gs[1])\n",
    "ax1.scatter(X_test1_PCA.loc[:, 0], X_test1_PCA.loc[:, 1], color = 'grey')\n",
    "ax1.set_xlabel('PC1')\n",
    "ax1.set_ylabel('PC2')\n",
    "ax1.set_xlim(-xlims, xlims)\n",
    "ax1.set_ylim(-xlims, xlims)\n",
    "ax1.set_title('Test Data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718a8f8",
   "metadata": {},
   "source": [
    "The test data (above right) that is projected into the training (normal operating) PCA space is more spread out.  It should be possible to use this distribution to identify anomaly windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Calculate Mahalanobis Distance \n",
    "# This is a multivatiate distance from centroid calculation that\n",
    "# can be useful for unsupervised anomaly detection\n",
    "data_train = np.array(X_train_PCA.values)\n",
    "data_test1 = np.array(X_test1_PCA.values)\n",
    "\n",
    "cov_matrix = np.cov(data_train, rowvar = False)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "\n",
    "# Mean of each column: PC1, PC2, etc. (it should be very close to zero)\n",
    "mean_distr = data_train.mean(axis = 0) # axis=0 means that average is computed per column\n",
    "np.set_printoptions(precision = 3, suppress = False)\n",
    "print('Mean distr', mean_distr)\n",
    "\n",
    "# Mahalanobis Distance calculation\n",
    "dist_test1 = pdm.MahalanobisDist(inv_cov_matrix, mean_distr, data_test1, verbose=False)\n",
    "dist_train = pdm.MahalanobisDist(inv_cov_matrix, mean_distr, data_train, verbose=False)\n",
    "\n",
    "print(\"Minimum & maximum MD in training set:\", min(dist_train), max(dist_train))\n",
    "print(\"Minimum & maximum MD in test set 1  :\", min(dist_test1), max(dist_test1))\n",
    "\n",
    "threshold = pdm.MD_threshold(dist_train, extreme = True) # extreme = True; 2x mean of incoming data\n",
    "print(\"Threshold value for flagging an anomaly is\", \"{:.2f}\".format(threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6236e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data & plot\n",
    "mh_dat = df_set_scaled[['timestamp', 'v5']]\n",
    "mh_train = pd.DataFrame({'timestamp':df_train.index, 'dist_train':dist_train})\n",
    "mh_dat = pd.merge(mh_dat, mh_train, how='left', on='timestamp')\n",
    "mh_test1 = pd.DataFrame({'timestamp':df_test1.index, 'dist_test1':dist_test1})\n",
    "mh_dat = pd.merge(mh_dat, mh_test1, how='left', on='timestamp')\n",
    "mh_dat['threshold'] = threshold\n",
    "\n",
    "# Visualize Mahalonobis distance with actual anomalies vs threshold  \n",
    "fig, ax = plt.subplots(figsize = (18, 4))\n",
    "ax.plot(mh_dat['timestamp'], mh_dat['dist_train'], color = 'lightgrey', marker = '.', zorder = 1, label = 'MhD Normal')\n",
    "ax.scatter(mh_dat['timestamp'], mh_dat['dist_test1'], color = 'orange', marker = '.', zorder = 2, label = 'MhD Abnormal')\n",
    "ax.plot(mh_dat['timestamp'], mh_dat['threshold'], color = 'red', marker = None, zorder = 3, linewidth=3, label = 'Threshold')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa6b79",
   "metadata": {},
   "source": [
    "The above plot shows the Mahalonobis distance (MhD) calculated for 'normal' data in grey and 'abnormal' data in orange.  The red line is the threshold for MhD as calculated above (based on a factor times the mean).  All points above the threshold would be classified as an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e723aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distrubution of Mahalobis distance\n",
    "plt.figure()\n",
    "sns.distplot(dist_train, bins = 200, kde = True, color = 'green')\n",
    "plt.xlim([0.0, 18])\n",
    "plt.xlabel('Mahalanobis dist')\n",
    "plt.title('Mahalanobis distance distribution for the training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6eca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Mahalonobis distance is above threshold: Flag as anomaly\n",
    "anomaly_train = pdm.prep_mahalonobis_data(dist_train, threshold, X_train_PCA)\n",
    "anomaly1 = pdm.prep_mahalonobis_data(dist_test1, threshold, X_test1_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071c5eb",
   "metadata": {},
   "source": [
    "From the above results, 1.9% of normal data has been classified as an anomaly (False Positives) and 34% of anomaly window points are classified as an anomaly.  We need to process this data further in order to calculate what percentage of anomaly windows have been identified as an anomaly, i.e., at least one point within the window classified as an anomaly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c67e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets define plot xlims for each anomaly window plot.\n",
    "# We want to be able to plot each window independently to assess model performance.\n",
    "df_ser = df_set.loc[df_set['status'] == 'Abnormal',:]\n",
    "n_plots = len(df_ser)\n",
    "buff = 20\n",
    "start_win = []\n",
    "ender_win = []\n",
    "for r in range(n_plots):\n",
    "    start_win.append(df_ser.iloc[r, 12] - buff)\n",
    "    ender_win.append(df_ser.iloc[r, 12] + buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing data to gaps between anomalies\n",
    "df_set.reset_index(drop = True, inplace = True)\n",
    "anomaly_train.reset_index(drop = True, inplace = True)\n",
    "preds_test = pd.merge(df_set, anomaly_train, how='left', on='timestamp')\n",
    "anomaly1.reset_index(drop = True, inplace = True)\n",
    "preds_test = pd.merge(df_set['timestamp'], anomaly1, how='left', on='timestamp')\n",
    "\n",
    "# Now lets count the number of anomaly windows \n",
    "# and check each window for a breach of the threshold\n",
    "# i.e., at least one point breaching the threshold in the window\n",
    "preds_test.loc[preds_test['Thresh'].isnull(), 'zone'] = 'Normal'\n",
    "preds_test.loc[preds_test['Thresh'].notnull(), 'zone'] = 'Anomaly'\n",
    "preds_test['anomaly_number'] = 0\n",
    "preds_test['v5'] = df_set_scaled['v5']\n",
    "preds_test['status'] = df_set_scaled['status']\n",
    "\n",
    "# Create some params that will help with visualization of anomaly \n",
    "# windows + analysis of prediction results \n",
    "preds_test = preds_test.assign(v5_win = preds_test['v5'])\n",
    "preds_test.loc[preds_test['zone'] == 'Normal', ['v5_win']] = None\n",
    "preds_test = preds_test.assign(v5_win_anom = preds_test['v5'])\n",
    "preds_test.loc[preds_test['prediction'] != 1, ['v5_win_anom']] = None\n",
    "preds_test.loc[preds_test['zone'] != 'Anomaly', ['v5_win_anom']] = None\n",
    "preds_test = preds_test.assign(v5_win_actual_anom = preds_test['v5'])\n",
    "preds_test.loc[preds_test['status'] != 'Abnormal', ['v5_win_actual_anom']] = None\n",
    "preds_test = preds_test.assign(v5_false_pos = preds_test['v5'])\n",
    "preds_test.loc[preds_test['prediction'] != 1, ['v5_false_pos']] = None\n",
    "preds_test.loc[preds_test['zone'] != 'Normal', ['v5_false_pos']] = None\n",
    "#preds_test.iloc[10690:10715,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458dfc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create zones of normal and abnormal for run length encoding\n",
    "Use rle for checking if an anomaly was detected in anomaly zone/window\n",
    "    rule_type 1: Simple check for presence of anomaly\n",
    "    rule_type 1: Check for max distance in window and comapre to threshold\n",
    "\n",
    "\"\"\"\n",
    "def calculate_anomaly_zone_acc(dat, rule_type=1):\n",
    "    # Calculate the run length encoding\n",
    "    rle_anomalies = [(k, sum(1 for i in g)) for k, g in groupby(dat['zone'])]\n",
    "\n",
    "    # Loop through & number anomaly windows based on run length encoding\n",
    "    dat['anomaly_number'] = 0\n",
    "    prev = 0\n",
    "    counter = 1\n",
    "    for j in range(len(rle_anomalies)):\n",
    "        if rle_anomalies[j][0] == 'Normal':\n",
    "            prev = prev + rle_anomalies[j][1]\n",
    "            next\n",
    "        elif j == 0:\n",
    "            prev = prev + rle_anomalies[j][1]\n",
    "            dat.loc[dat.index.isin(list(range(0, rle_anomalies[j][1], 1))), 'anomaly_number'] = counter \n",
    "            counter += 1\n",
    "        else:        \n",
    "            goto = prev + rle_anomalies[j][1]\n",
    "            dat.loc[dat.index.isin(list(range(prev, goto, 1))), 'anomaly_number'] = counter\n",
    "            prev = prev + rle_anomalies[j][1]\n",
    "            counter += 1\n",
    "\n",
    "    # Now summarise and count how many were missed, i.e., false negatives\n",
    "    count_anomaly_blks = dat.loc[dat['anomaly_number'] != 0,:]\n",
    "    count_anomaly_blks = max(count_anomaly_blks['anomaly_number'])\n",
    "    anom_chk = []\n",
    "    anom_num = []\n",
    "   \n",
    "    for a in range(count_anomaly_blks):\n",
    "        anom_num.append(a + 1)\n",
    "        dat_tmp = dat.loc[dat['anomaly_number'] == a + 1,:]\n",
    "        if rule_type == 1:\n",
    "            pred = max(dat_tmp['prediction'])    \n",
    "            if pred == 1:\n",
    "                anom_chk.append(1)\n",
    "            else: \n",
    "                anom_chk.append(0)\n",
    "        elif rule_type == 2:\n",
    "            max_mobdi = max(dat_tmp['Mob dist'])\n",
    "            max_thres = max(dat_tmp['Thresh'])\n",
    "            if max_mobdi >= max_thres:\n",
    "                anom_chk.append(1)\n",
    "            else: \n",
    "                anom_chk.append(0)\n",
    "        else:\n",
    "            print('Invalid rule type specified...')\n",
    "\n",
    "    result_summary = pd.DataFrame()\n",
    "    result_summary['anom_num'] = anom_num\n",
    "    result_summary['anom_chk'] = anom_chk\n",
    "    FN = len(result_summary.loc[result_summary['anom_chk'] == 0,:])\n",
    "    TP = len(result_summary.loc[result_summary['anom_chk'] == 1,:])\n",
    "    AP = len(result_summary)\n",
    "    FN_per = round(100*FN/AP, 2)\n",
    "    TP_per = round(100*TP/AP, 2)\n",
    "    print('Model performance for anomaly windows:')\n",
    "    print('======================================')\n",
    "    print(f'Found {TP} out of {AP} (TP: {TP_per}%)')\n",
    "    print(f'Missed {FN} out of {AP} (FN: {FN_per}%)\\n')    \n",
    "    print(result_summary.loc[result_summary['anom_chk'] == 0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_anomaly_zone_acc(preds_test, rule_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04955c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets plot each window and verify the results\n",
    "# Inspect the windows that were missed (false negatives)\n",
    "\n",
    "# By default, plot only a selection of 20 plots (randomly selected)\n",
    "# Note: It takes a few minutes to plot all & can consume a lot of memory.\n",
    "PLOT_ALL = False\n",
    "\n",
    "random_list = []\n",
    "for i in range(0, 20):\n",
    "    n = random.randint(1, n_plots)\n",
    "    random_list.append(n)\n",
    "\n",
    "if PLOT_ALL:\n",
    "    plots_list = range(n_plots)\n",
    "else:\n",
    "    plots_list = random_list\n",
    "    \n",
    "for p in plots_list:\n",
    "    fig, ax = plt.subplots(figsize = (10, 4))\n",
    "    ax.plot(preds_test['timestamp'], preds_test['v5'], color = 'lightgrey', marker = '.', zorder = 1, label = 'v5 sensor')        \n",
    "    ax.plot(preds_test['timestamp'], preds_test['v5_win'], color = 'orange', marker = 'o', zorder = 2, linewidth = 3, label = f'Anomaly window {p+1}')\n",
    "    ax.plot(preds_test['timestamp'], preds_test['v5_win_anom'], color = 'purple', marker = 'o', zorder = 2, linewidth = 3, label = 'Predicted anomaly')\n",
    "    ax.scatter(preds_test['timestamp'], preds_test['v5_win_actual_anom'], color = 'red', marker = 'X', s = 200, zorder = 3, label = 'Actual anomaly')\n",
    "    ax.scatter(preds_test['timestamp'], preds_test['v5_false_pos'], color ='green', marker = 'X', s = 100, zorder = 2, label = 'False positive')\n",
    "    ax.legend(loc = 'lower right')        \n",
    "    ax.set_ylim(10, -10)\n",
    "    ax.set_xlim(start_win[p], ender_win[p])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0783d25",
   "metadata": {},
   "source": [
    "The above plots show each of the anomaly windows using sensor v5 as a backdrop.  The anomaly window is show using orange highlighted points and line.  Purple points are points that have been classified as anomalies by the model.  The actual point that is labelled as an anomaly in the dataset is shown with a red 'X'.  False positives are shown using a green 'X' (where the appear in the plot windows). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620899d",
   "metadata": {},
   "source": [
    "### MODEL 2. Clustering & Euclidean Distance\n",
    "Try a K-means clustering approach where we group together usual combinations of features. The points that are far from the cluster are points with an unusual combination of features and these points will be classified as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281418c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remind ourselves of the base data with the 11x features\n",
    "df_num = df_set.drop(['status', 'timestamp'], axis = 1)\n",
    "df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e612b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "data = df_set.drop(['status', 'timestamp'], axis = 1)\n",
    "scaler1 = preprocessing.StandardScaler()\n",
    "np_scaled = scaler1.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)\n",
    "\n",
    "# Reduce to 2 PCA features\n",
    "pca = PCA(n_components=2)\n",
    "data = pca.fit_transform(data)\n",
    "\n",
    "# Standardize these 2 new features\n",
    "scaler2 = preprocessing.StandardScaler()\n",
    "np_scaled = scaler2.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)\n",
    "\n",
    "# Evaluate effect of using robust PCA \n",
    "# Robust PCA\n",
    "#L, S = pdm.R_pca(df_set.drop(['status', 'timestamp'], axis = 1)).fit()\n",
    "#scaler3 = preprocessing.StandardScaler()\n",
    "#np_scaled = scaler3.fit_transform(L)\n",
    "#data = pd.DataFrame(np_scaled)\n",
    "\n",
    "# Reduce to 2 PCA features\n",
    "#rpca = PCA(n_components=2)\n",
    "#data = rpca.fit_transform(data)\n",
    "\n",
    "# Standardize these 2 new features\n",
    "#scaler4 = preprocessing.StandardScaler()\n",
    "#np_scaled = scaler4.fit_transform(data)\n",
    "#data = pd.DataFrame(np_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate with different numbers of centroids & plot the loss (elbow method)\n",
    "n_cluster = range(1, 20)\n",
    "kmeans = [KMeans(n_clusters=i, random_state=1234).fit(data) for i in n_cluster]\n",
    "scores = [kmeans[i].score(data) for i in range(len(kmeans))]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_cluster, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2dc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 15 centroids & add these data to the base dataframe\n",
    "#kmeans_model = KMeans(n_clusters=15, random_state=1234).fit(data)\n",
    "df = df_num\n",
    "df['cluster'] = kmeans[14].predict(data)\n",
    "df['principal_feature1'] = data[0]\n",
    "df['principal_feature2'] = data[1]\n",
    "df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4070ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different clusters with the 2x PCA component features\n",
    "fig, ax = plt.subplots()\n",
    "colors = {0:'red', 1:'blue', 2:'green', 3:'pink', 4:'black', 5:'orange', 6:'cyan', 7:'yellow', 8:'brown', 9:'purple', 10:'white', 11: 'grey', 12:'lightblue', 13:'lightgreen', 14: 'darkgrey'}\n",
    "ax.scatter(df['principal_feature1'], df['principal_feature2'], c=df[\"cluster\"].apply(lambda x: colors[x]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebcf3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a function that returns a list of distances \n",
    "between each point & its distance to the closest centroid\n",
    "Use 'np.linalg.norm' as the Euclidean distance is the l2 norm, \n",
    "and the default value of the ord parameter in numpy.linalg.norm is 2.\n",
    "\"\"\"\n",
    "def getDistanceByPoint(dat, model):\n",
    "    distance = []\n",
    "    for i in range(0, len(dat)):\n",
    "        Xa = np.array(dat.loc[i])\n",
    "        Xb = model.cluster_centers_[model.labels_[i] - 1]\n",
    "        distance.append(np.linalg.norm(Xa - Xb))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe857ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the distance between each point and its nearest centroid. \n",
    "# The biggest distances will be considered as anomalies (using outlier_fraction assumption)\n",
    "distance = pd.Series(getDistanceByPoint(data, kmeans[14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04463ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(distance, bins = 200, kde = True, color = 'green');\n",
    "plt.xlim([0.0, 18])\n",
    "plt.xlabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.10\n",
    "number_of_outliers = int(outliers_fraction * len(distance))\n",
    "threshold = distance.nlargest(number_of_outliers).min()\n",
    "\n",
    "# Prediction will contain the anomaly result (0:normal, 1:anomaly) \n",
    "df['prediction'] = (distance >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56fb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Selected anomaly percentage: {100 * outliers_fraction}%')\n",
    "print('Selected threshold distance:', round(threshold, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of anomaly with cluster view\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Use a simple color mapping\n",
    "colors = {0:'lightgrey', 1:'red'}\n",
    "\n",
    "# Now plot\n",
    "ax.scatter(df['principal_feature1'], df['principal_feature2'], c = df['prediction'].apply(lambda x: colors[x]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick overview visualisation of anomaly detection through time\n",
    "fig, ax = plt.subplots(figsize = (18, 4))\n",
    "\n",
    "a = df.loc[df['prediction'] == 1, ['v5']] # anomaly using v5 sensor as backdrop\n",
    "\n",
    "ax.plot(df.index, df['v5'], color='lightgrey', zorder=1, label = 'v5 sensor')\n",
    "ax.scatter(a.index, a['v5'], color='red', marker='.', zorder=2, label = 'Predicted Anomaly')\n",
    "ax.legend(loc = 'lower right')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc3b978",
   "metadata": {},
   "source": [
    "Anomalies appear to be reasonably well distributed in the expected zones.  Let's move on to evaluate the results in more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d2dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the anomaly fraction (outlier fraction), should be what we\n",
    "# we set it to in outlier_fraction\n",
    "anomaly_count = round(100*len(a)/len(df), 2)\n",
    "print(f'Anomaly fraction check is {anomaly_count}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the zone (Normal or Anomaly) to the dataframe we are using to analyse results\n",
    "# Let's also recheck row counts\n",
    "df['zone'] = 'tbc'\n",
    "df.loc[df.index.isin(df_train.index), 'zone'] = 'Normal'\n",
    "df.loc[df.index.isin(df_test1.index), 'zone'] = 'Anomaly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f11d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_norm = sum(df['zone'] == 'Normal')\n",
    "count_anom = sum(df['zone'] == 'Anomaly')\n",
    "print(f'Check normal point count: {\"{:,}\".format(count_norm)}')\n",
    "print(f'Check anomaly zone point count:, {\"{:,}\".format(count_anom)}')\n",
    "print('Check tbc count (should be zero):', sum(df['zone'] == 'tbc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc971c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep a prediction summary for plotting & analysis of results\n",
    "if 'preds_test' in globals(): del preds_test\n",
    "preds_test = df\n",
    "preds_test['timestamp'] = preds_test.index\n",
    "preds_test['status'] = df_set_scaled['status']\n",
    "\n",
    "# Create some params that will help with visualization of anomaly \n",
    "# windows + analysis of prediction results \n",
    "preds_test = preds_test.assign(v5_win = preds_test['v5'])\n",
    "preds_test.loc[preds_test['zone'] == 'Normal', ['v5_win']] = None\n",
    "preds_test = preds_test.assign(v5_win_anom = preds_test['v5'])\n",
    "preds_test.loc[preds_test['prediction'] != 1, ['v5_win_anom']] = None\n",
    "preds_test.loc[preds_test['zone'] != 'Anomaly', ['v5_win_anom']] = None\n",
    "preds_test = preds_test.assign(v5_win_actual_anom = preds_test['v5'])\n",
    "preds_test.loc[preds_test['status'] != 'Abnormal', ['v5_win_actual_anom']] = None\n",
    "preds_test = preds_test.assign(v5_false_pos = preds_test['v5'])\n",
    "preds_test.loc[preds_test['prediction'] != 1, ['v5_false_pos']] = None\n",
    "preds_test.loc[preds_test['zone'] != 'Normal', ['v5_false_pos']] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469db14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output is as expected\n",
    "#preds_test.loc[10690:10715,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy for anomaly zone predictions\n",
    "calculate_anomaly_zone_acc(preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b575b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a function to evaluate accuracy in the normal zones\n",
    "Key focus here will be false positive rate, this should be as low as possible\n",
    "for an effective solution (i.e., mininse number of 'false alarms')\n",
    "\"\"\"\n",
    "def calculate_normal_zone_acc(dat):\n",
    "    norm_rows = dat.loc[preds_test['zone'] == 'Normal', ['zone', 'prediction']]\n",
    "    AR = len(norm_rows)\n",
    "    print('Model performance for normal windows:')\n",
    "    print('======================================')\n",
    "    print('Total rows:', \"{:,}\".format(AR))\n",
    "    TN = len(norm_rows.loc[norm_rows['prediction'] == 0, ['zone', 'prediction']])\n",
    "    FP = len(norm_rows.loc[norm_rows['prediction'] == 1, ['zone', 'prediction']])\n",
    "    print(f'TN: True negative (normal pts correctly assigned normal): {\"{:,}\".format(TN)} ({round(100*TN/AR, 2)}%)')\n",
    "    print(f'FP: False positive (normal pts incorrectly assigned anomaly): {\"{:,}\".format(FP)} ({round(100*FP/AR, 2)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506fc5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_normal_zone_acc(preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045605c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets plot each window and verify the results\n",
    "# Inspect the windows that were missed (false negatives)\n",
    "\n",
    "# By default, plot only a selection of 20 plots (randomly selected)\n",
    "# Note: It takes a few minutes to plot all & can consume a lot of memory.\n",
    "PLOT_ALL = False\n",
    "\n",
    "random_list = []\n",
    "for i in range(0, 20):\n",
    "    n = random.randint(1, n_plots)\n",
    "    random_list.append(n)\n",
    "\n",
    "if PLOT_ALL:\n",
    "    plots_list = range(n_plots)\n",
    "else:\n",
    "    plots_list = random_list\n",
    "    \n",
    "for p in plots_list:\n",
    "    fig, ax = plt.subplots(figsize = (10, 4))\n",
    "    ax.plot(preds_test['timestamp'], preds_test['v5'], color = 'lightgrey', marker = '.', zorder = 1, label = 'v5 sensor')        \n",
    "    ax.plot(preds_test['timestamp'], preds_test['v5_win'], color = 'orange', marker = 'o', zorder = 2, linewidth = 3, label = f'Anomaly window {p+1}')\n",
    "    ax.plot(preds_test['timestamp'], preds_test['v5_win_anom'], color = 'purple', marker = 'o', zorder = 2, linewidth = 3, label = 'Predicted anomaly')\n",
    "    ax.scatter(preds_test['timestamp'], preds_test['v5_win_actual_anom'], color = 'red', marker = 'X', s = 200, zorder = 3, label = 'Actual anomaly')\n",
    "    ax.scatter(preds_test['timestamp'], preds_test['v5_false_pos'], color ='green', marker = 'X', s = 100, zorder = 2, label = 'False positive')\n",
    "    ax.legend(loc = 'lower right')        \n",
    "    ax.set_ylim(10, -10)\n",
    "    ax.set_xlim(start_win[p], ender_win[p])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aaba89",
   "metadata": {},
   "source": [
    "### MODEL 3. One-class Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b9206",
   "metadata": {},
   "source": [
    "SVMs use hyperplanes in multi-dimensional space to separate one class of observations from another. In a one-class SVM problem, all data belongs to a single class (often the normal class). The model is trained to learn these 'normal' conditions, so that when a new data is encountered, it can identify whether it should belong to trained class or not. If not, the new data is labeled as an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac047a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a one-class SVM \n",
    "# nu = contamination \n",
    "svm_model =  OneClassSVM(nu = 0.01) \n",
    "svm_model.fit(pd.DataFrame(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827fd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for train set \n",
    "preds = pd.Series(svm_model.predict(df_train))\n",
    "test = pd.DataFrame({'v5':pd.Series(df_train['v5'])})\n",
    "svm_out = pd.DataFrame({'timestamp':df_train.index, 'Prediction':preds})\n",
    "v5 = df_train['v5']\n",
    "v5 = v5.reset_index()\n",
    "v5.drop('timestamp', axis = 1, inplace = True)\n",
    "svm_out['v5'] = v5\n",
    "svm_out['Prediction'] = svm_out['Prediction'].map({1: 0, -1: 1})\n",
    "svm_aly = svm_out.loc[svm_out['Prediction'] == 1, ['timestamp', 'v5']] # anomaly\n",
    "print(str(len(svm_aly)) + ' out of ' + str(len(svm_out)) + ' (' + str(round(100 * (len(svm_aly) / len(svm_out)), 2)) + '%)')\n",
    "svm_aly0 = svm_aly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for test set\n",
    "preds = pd.Series(svm_model.predict(df_test1))\n",
    "test = pd.DataFrame({'v5':pd.Series(df_test1['v5'])})\n",
    "svm_out = pd.DataFrame({'timestamp':df_test1.index, 'Prediction':preds})\n",
    "v5 = df_test1['v5']\n",
    "v5 = v5.reset_index()\n",
    "v5.drop('timestamp', axis = 1, inplace = True)\n",
    "svm_out['v5'] = v5\n",
    "svm_out['Prediction'] = svm_out['Prediction'].map({1: 0, -1: 1})\n",
    "svm_aly = svm_out.loc[svm_out['Prediction'] == 1, ['timestamp', 'v5']] # anomaly\n",
    "print(str(len(svm_aly)) + ' out of ' + str(len(svm_out)) + ' (' + str(round(100 * (len(svm_aly) / len(svm_out)), 2)) + '%)')\n",
    "svm_aly1 = svm_aly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d8898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reword results so that we can drill into them in more detail\n",
    "df_all = df_set_scaled.drop(['status', 'timestamp', 'id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16abbcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'preds_test' in globals(): del preds_test\n",
    "preds_test = pd.DataFrame({'prediction':svm_model.predict(df_all)})\n",
    "preds_test['timestamp'] = df_set_scaled.index\n",
    "preds_test['prediction'] = preds_test['prediction'].map({1: 0, -1: 1})\n",
    "preds_test['status'] = df_set_scaled['status']\n",
    "preds_test.loc[preds_test['timestamp'].isin(df_train.index), 'zone'] = 'Normal'\n",
    "preds_test.loc[preds_test['timestamp'].isin(df_test1.index), 'zone'] = 'Anomaly'\n",
    "preds_test['v5'] = df_set_scaled['v5'] \n",
    "\n",
    "# Create some params that will help with visualization of anomaly \n",
    "# windows + analysis of prediction results \n",
    "preds_test = preds_test.assign(v5_win = preds_test['v5'])\n",
    "preds_test.loc[preds_test['zone'] == 'Normal', ['v5_win']] = None\n",
    "preds_test = preds_test.assign(v5_win_anom = preds_test['v5'])\n",
    "preds_test.loc[preds_test['prediction'] != 1, ['v5_win_anom']] = None\n",
    "preds_test.loc[preds_test['zone'] != 'Anomaly', ['v5_win_anom']] = None\n",
    "preds_test = preds_test.assign(v5_win_actual_anom = preds_test['v5'])\n",
    "preds_test.loc[preds_test['status'] != 'Abnormal', ['v5_win_actual_anom']] = None\n",
    "preds_test = preds_test.assign(v5_false_pos = preds_test['v5'])\n",
    "preds_test.loc[preds_test['prediction'] != 1, ['v5_false_pos']] = None\n",
    "preds_test.loc[preds_test['zone'] != 'Normal', ['v5_false_pos']] = None\n",
    "#preds_test.iloc[10690:10715,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5161b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_normal_zone_acc(preds_test)\n",
    "print('\\n')\n",
    "calculate_anomaly_zone_acc(preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccce220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output is as expected\n",
    "#preds_test.loc[10690:10710,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets plot each window and verify the results\n",
    "# Inspect the windows that were missed (false negatives)\n",
    "PLOT_WINS = True\n",
    "if PLOT_WINS:\n",
    "    for p in range(n_plots):\n",
    "        fig, ax = plt.subplots(figsize = (10, 4))\n",
    "        ax.plot(preds_test['timestamp'], preds_test['v5'], color = 'lightgrey', marker = '.', zorder = 1, label = 'v5 sensor')        \n",
    "        ax.plot(preds_test['timestamp'], preds_test['v5_win'], color = 'orange', marker = 'o', zorder = 2, linewidth = 3, label = f'Anomaly window {p+1}')\n",
    "        ax.plot(preds_test['timestamp'], preds_test['v5_win_anom'], color = 'purple', marker = 'o', zorder = 2, linewidth = 3, label = 'Predicted anomaly')\n",
    "        ax.scatter(preds_test['timestamp'], preds_test['v5_win_actual_anom'], color = 'red', marker = 'X', s = 200, zorder = 3, label = 'Actual anomaly')\n",
    "        ax.scatter(preds_test['timestamp'], preds_test['v5_false_pos'], color ='green', marker = 'X', s = 100, zorder = 2, label = 'False positive')\n",
    "        ax.legend(loc = 'lower right')        \n",
    "        ax.set_ylim(10, -10)\n",
    "        ax.set_xlim(start_win[p], ender_win[p])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (18, 4))\n",
    "ax.plot(preds_test['timestamp'], preds_test['v5'], color = 'lightgrey', marker = '.', zorder = 1, label = 'Normal')        \n",
    "ax.plot(preds_test['timestamp'], preds_test['v5_win_anom'], color = 'orange', marker = 'o', zorder = 3, linewidth = 3, label = f'Anomaly Window {p+1}')\n",
    "ax.scatter(preds_test['timestamp'], preds_test['v5_win_actual_anom'], color = 'red', marker = 'X', zorder = 4, label = 'Actual Anomaly')\n",
    "ax.scatter(preds_test['timestamp'], preds_test['v5_false_pos'], color ='green', marker = '.', zorder = 2, label = 'Anomaly: Normal Time')\n",
    "ax.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6769d95",
   "metadata": {},
   "source": [
    "### MODEL 4. Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec14e4c",
   "metadata": {},
   "source": [
    "An Isolation Forest is a tree-based unsupervised model.  In an Isolation Forest, randomly sub-sampled data are processed in a tree structure based on randomly selected features. Samples that travel deeper into the tree are less likely to be anomalies as they required more cuts to isolate them. Similarly, the samples which end up in shorter branches indicate anomalies as it was easier for the tree to separate them from other observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train isolation forest \n",
    "isfo_model =  IsolationForest(contamination = 0.01)\n",
    "isfo_model.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00136844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for train set (normal operating)\n",
    "preds = pd.Series(isfo_model.predict(df_train))\n",
    "test = pd.DataFrame({'v5':pd.Series(df_train['v5'])})\n",
    "isfo_out = pd.DataFrame({'timestamp':df_train.index, 'Prediction':preds})\n",
    "v5 = df_train['v5']\n",
    "v5 = v5.reset_index()\n",
    "v5.drop('timestamp', axis = 1, inplace = True)\n",
    "isfo_out['v5'] = v5\n",
    "isfo_out['Prediction'] = isfo_out['Prediction'].map({1: 0, -1: 1})\n",
    "isfo_aly = isfo_out.loc[isfo_out['Prediction'] == 1, ['timestamp', 'v5']] # anomaly\n",
    "print(str(len(isfo_aly)) + ' out of ' + str(len(isfo_out)) + ' (' + str(round(100 * (len(isfo_aly) / len(isfo_out)), 2)) + '%)')\n",
    "isfo_aly0 = isfo_aly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30684ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for test set\n",
    "preds = pd.Series(isfo_model.predict(df_test1))\n",
    "test = pd.DataFrame({'v5':pd.Series(df_test1['v5'])})\n",
    "isfo_out = pd.DataFrame({'timestamp':df_test1.index, 'Prediction':preds})\n",
    "v5 = df_test1['v5']\n",
    "v5 = v5.reset_index()\n",
    "v5.drop('timestamp', axis = 1, inplace = True)\n",
    "isfo_out['v5'] = v5\n",
    "isfo_out['Prediction'] = isfo_out['Prediction'].map({1: 0, -1: 1})\n",
    "isfo_aly = isfo_out.loc[isfo_out['Prediction'] == 1, ['timestamp', 'v5']] # anomaly\n",
    "print(str(len(isfo_aly)) + ' out of ' + str(len(isfo_out)) + ' (' + str(round(100 * (len(isfo_aly) / len(isfo_out)), 2)) + '%)')\n",
    "isfo_aly1 = isfo_aly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161869f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'preds_test' in globals(): del preds_test\n",
    "preds_test = pd.DataFrame({'prediction':isfo_model.predict(df_all)})\n",
    "preds_test['timestamp'] = df_set_scaled.index\n",
    "preds_test['prediction'] = preds_test['prediction'].map({1: 0, -1: 1})\n",
    "preds_test['status'] = df_set_scaled['status']\n",
    "preds_test.loc[preds_test['timestamp'].isin(df_train.index), 'zone'] = 'Normal'\n",
    "preds_test.loc[preds_test['timestamp'].isin(df_test1.index), 'zone'] = 'Anomaly'\n",
    "preds_test['v5'] = df_set_scaled['v5'] \n",
    "\n",
    "# Create some params that will help with visualization of anomaly \n",
    "# windows + analysis of prediction results \n",
    "preds_test = preds_test.assign(v5_win = preds_test['v5'])\n",
    "preds_test.loc[preds_test['zone'] == 'Normal', ['v5_win']] = None\n",
    "preds_test = preds_test.assign(v5_win_anom = preds_test['v5'])\n",
    "preds_test.loc[preds_test['prediction'] != 1, ['v5_win_anom']] = None\n",
    "preds_test.loc[preds_test['zone'] != 'Anomaly', ['v5_win_anom']] = None\n",
    "preds_test = preds_test.assign(v5_win_actual_anom = preds_test['v5'])\n",
    "preds_test.loc[preds_test['status'] != 'Abnormal', ['v5_win_actual_anom']] = None\n",
    "preds_test = preds_test.assign(v5_false_pos = preds_test['v5'])\n",
    "preds_test.loc[preds_test['prediction'] != 1, ['v5_false_pos']] = None\n",
    "preds_test.loc[preds_test['zone'] != 'Normal', ['v5_false_pos']] = None\n",
    "#preds_test.iloc[10690:10715,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb77519",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_normal_zone_acc(preds_test)\n",
    "print('\\n')\n",
    "calculate_anomaly_zone_acc(preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd24c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets plot each window and verify the results\n",
    "# Inspect the windows that were missed (false negatives)\n",
    "PLOT_WINS = True\n",
    "if PLOT_WINS:\n",
    "    for p in range(n_plots):\n",
    "        fig, ax = plt.subplots(figsize = (10, 4))\n",
    "        ax.plot(preds_test['timestamp'], preds_test['v5'], color = 'lightgrey', marker = '.', zorder = 1, label = 'v5 sensor')        \n",
    "        ax.plot(preds_test['timestamp'], preds_test['v5_win'], color = 'orange', marker = 'o', zorder = 2, linewidth = 3, label = f'Anomaly window {p+1}')\n",
    "        ax.plot(preds_test['timestamp'], preds_test['v5_win_anom'], color = 'purple', marker = 'o', zorder = 2, linewidth = 3, label = 'Predicted anomaly')\n",
    "        ax.scatter(preds_test['timestamp'], preds_test['v5_win_actual_anom'], color = 'red', marker = 'X', s = 200, zorder = 3, label = 'Actual anomaly')\n",
    "        ax.scatter(preds_test['timestamp'], preds_test['v5_false_pos'], color ='green', marker = 'X', s = 100, zorder = 2, label = 'False positive')\n",
    "        ax.legend(loc = 'lower right')        \n",
    "        ax.set_ylim(10, -10)\n",
    "        ax.set_xlim(start_win[p], ender_win[p])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8600a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (18, 4))\n",
    "ax.plot(preds_test['timestamp'], preds_test['v5'], color = 'lightgrey', marker = '.', zorder = 1, label = 'Normal')        \n",
    "ax.plot(preds_test['timestamp'], preds_test['v5_win_anom'], color = 'orange', marker = 'o', zorder = 3, linewidth = 3, label = f'Anomaly Window {p+1}')\n",
    "ax.scatter(preds_test['timestamp'], preds_test['v5_win_actual_anom'], color = 'red', marker = 'X', zorder = 4, label = 'Actual Anomaly')\n",
    "ax.scatter(preds_test['timestamp'], preds_test['v5_false_pos'], color ='green', marker = '.', zorder = 2, label = 'Anomaly: Normal Time')\n",
    "ax.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac8509",
   "metadata": {},
   "source": [
    "### MODEL 5. Autoencoder LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b60567",
   "metadata": {},
   "source": [
    "An autoencoder is a type of ANN that is used to learn efficient codings of unlabeled data (i.e., unsupervised learning).  In this autoencoder model, Long Short-Term Memory (LSTM) neural network cells are used. LSTM networks are a sub-type of the more general recurrent neural networks (RNN). A key attribute of recurrent neural networks is their ability to persist information, or cell state, for use later in the network. This makes them particularly well suited for analysis of time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "sns.set(color_codes = True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44bd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed(13)\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh the data\n",
    "df_train = df_train#.to_numpy()\n",
    "df_test1 = df_test1#.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3355e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape inputs for LSTM [samples, timesteps, features]\n",
    "X_train = df_train.reshape(df_train.shape[0], 1, df_train.shape[1])\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "\n",
    "X_test1 = df_test1.reshape(df_test1.shape[0], 1, df_test1.shape[1])\n",
    "print(\"Test data 1 shape:\", X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the autoencoder network model\n",
    "def autoencoder_model(X):\n",
    "    inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
    "    L1 = LSTM(64, activation='relu', return_sequences=True, \n",
    "              kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
    "    L2 = LSTM(4, activation='relu', return_sequences=False)(L1)\n",
    "    L3 = RepeatVector(X.shape[1])(L2)\n",
    "    L4 = LSTM(4, activation='relu', return_sequences=True)(L3)\n",
    "    L5 = LSTM(64, activation='relu', return_sequences=True)(L4)\n",
    "    output = TimeDistributed(Dense(X.shape[2]))(L5)    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the autoencoder model\n",
    "model = autoencoder_model(X_train)\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mae')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b953e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data\n",
    "nb_epochs = 20\n",
    "batch_size = 1000\n",
    "history = model.fit(X_train, X_train, epochs=nb_epochs, batch_size=batch_size, validation_split=0.10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec49f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training losses\n",
    "fig, ax = plt.subplots(figsize=(14, 6), dpi=80)\n",
    "ax.plot(history['loss'], 'b', label='Train', linewidth=2)\n",
    "ax.plot(history['val_loss'], 'r', label='Validation', linewidth=2)\n",
    "ax.set_title('Model loss', fontsize=16)\n",
    "ax.set_ylabel('Loss (mae)')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f029f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss distribution of the training set\n",
    "X_pred = model.predict(X_train)\n",
    "X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\n",
    "X_pred = pd.DataFrame(X_pred, columns=df_train.columns)\n",
    "X_pred.index = df_train.index\n",
    "\n",
    "scored = pd.DataFrame(index=df_train.index)\n",
    "Xtrain = X_train.reshape(X_train.shape[0], X_train.shape[2])\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-Xtrain), axis = 1)\n",
    "plt.figure(figsize=(16, 9), dpi=80)\n",
    "plt.title('Loss Distribution', fontsize=16)\n",
    "sns.distplot(scored['Loss_mae'], bins = 20, kde= True, color = 'blue');\n",
    "plt.xlim([0.0, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c40493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_test_loss(test, test_df, thresh):\n",
    "    # Calculate the loss on the test set 1\n",
    "    X_pred = model.predict(test)\n",
    "    X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\n",
    "    X_pred = pd.DataFrame(X_pred, columns=test_df.columns)\n",
    "    X_pred.index = test_df.index\n",
    "\n",
    "    scored = pd.DataFrame(index=test_df.index)\n",
    "    Xtest = test.reshape(test.shape[0], test.shape[2])\n",
    "    scored['Loss_mae'] = np.mean(np.abs(X_pred - Xtest), axis=1)\n",
    "    scored['Threshold'] = thresh\n",
    "    scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
    "    print(scored.head())\n",
    "    return(scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9d4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loss on the test set 1\n",
    "selected_threshold = 0.12\n",
    "scored1 = calc_test_loss(X_test1, df_test1, selected_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the same metrics for the training set \n",
    "# and merge all data in a single dataframe for plotting\n",
    "X_pred_train = model.predict(X_train)\n",
    "X_pred_train = X_pred_train.reshape(X_pred_train.shape[0], X_pred_train.shape[2])\n",
    "X_pred_train = pd.DataFrame(X_pred_train, columns=df_train.columns)\n",
    "X_pred_train.index = df_train.index\n",
    "\n",
    "scored_train = pd.DataFrame(index=df_train.index)\n",
    "scored_train['Loss_mae'] = np.mean(np.abs(X_pred_train-Xtrain), axis = 1)\n",
    "scored_train['Threshold'] = 0.12\n",
    "scored_train['Anomaly'] = scored_train['Loss_mae'] > scored_train['Threshold']\n",
    "\n",
    "scored = pd.concat([scored_train, scored1])\n",
    "scored.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ee352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bearing failure time plot\n",
    "scored.plot(logy = True,  figsize=(16, 9), ylim=[1e-2, 1e2], color=['blue','red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored['Threshold'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b91657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all model information, including weights, in h5 format\n",
    "model.save(\"auto_lstm_ak.h5\")\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511b916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
